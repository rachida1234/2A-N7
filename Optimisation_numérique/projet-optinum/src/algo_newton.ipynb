{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1> TP-Projet d'optimisation numérique </h1>\n",
    "<h1> Algorithme de Newton </h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implémentation \n",
    " \n",
    "1. Coder l’algorithme de Newton local en respectant la spécification ci-dessous (fichier `Algorithme_De_Newton.jl`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\paragraph{Objet}\n",
       "Cette fonction implémente l'algorithme de Newton pour résoudre un problème d'optimisation sans contraintes\n",
       "\n",
       "\\paragraph{Syntaxe}\n",
       "\\begin{verbatim}\n",
       "xmin,fmin,flag,nb_iters = Algorithme_de_Newton(f,gradf,hessf,x0,option)\n",
       "\\end{verbatim}\n",
       "\\paragraph{Entrées :}\n",
       "\\begin{itemize}\n",
       "\\item f       : (Function) la fonction à minimiser\n",
       "\n",
       "\n",
       "\\item gradf   : (Function) le gradient de la fonction f\n",
       "\n",
       "\n",
       "\\item hessf   : (Function) la hessienne de la fonction f\n",
       "\n",
       "\n",
       "\\item x0      : (Array\\{Float,1\\}) première approximation de la solution cherchée\n",
       "\n",
       "\n",
       "\\item options : (Array\\{Float,1\\})\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item max\\_iter      : le nombre maximal d'iterations\n",
       "\n",
       "\n",
       "\\item Tol\\_abs       : la tolérence absolue\n",
       "\n",
       "\n",
       "\\item Tol\\_rel       : la tolérence relative\n",
       "\n",
       "\n",
       "\\item epsilon       : epsilon pour les tests de stagnation\n",
       "\n",
       "\\end{itemize}\n",
       "\\end{itemize}\n",
       "\\paragraph{Sorties:}\n",
       "\\begin{itemize}\n",
       "\\item xmin    : (Array\\{Float,1\\}) une approximation de la solution du problème  : $\\min_{x \\in \\mathbb{R}^{n}} f(x)$\n",
       "\n",
       "\n",
       "\\item fmin    : (Float) $f(x_{min})$\n",
       "\n",
       "\n",
       "\\item flag    : (Integer) indique le critère sur lequel le programme s'est arrêté (en respectant cet ordre de priorité si plusieurs critères sont vérifiés)\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item 0    : CN1 \n",
       "\n",
       "\n",
       "\\item 1    : stagnation du xk\n",
       "\n",
       "\n",
       "\\item 2    : stagnation du f\n",
       "\n",
       "\n",
       "\\item 3    : nombre maximal d'itération dépassé\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\\item nb\\_iters : (Integer) le nombre d'itérations faites par le programme\n",
       "\n",
       "\\end{itemize}\n",
       "\\paragraph{Exemple d'appel}\n",
       "\\begin{verbatim}\n",
       "f(x)=100*(x[2]-x[1]^2)^2+(1-x[1])^2\n",
       "gradf(x)=[-400*x[1]*(x[2]-x[1]^2)-2*(1-x[1]) ; 200*(x[2]-x[1]^2)]\n",
       "hessf(x)=[-400*(x[2]-3*x[1]^2)+2  -400*x[1];-400*x[1]  200]\n",
       "x0 = [1; 0]\n",
       "options = []\n",
       "xmin,fmin,flag,nb_iters = Algorithme_De_Newton(f,gradf,hessf,x0,options)\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "#### Objet\n",
       "\n",
       "Cette fonction implémente l'algorithme de Newton pour résoudre un problème d'optimisation sans contraintes\n",
       "\n",
       "#### Syntaxe\n",
       "\n",
       "```julia\n",
       "xmin,fmin,flag,nb_iters = Algorithme_de_Newton(f,gradf,hessf,x0,option)\n",
       "```\n",
       "\n",
       "#### Entrées :\n",
       "\n",
       "  * f       : (Function) la fonction à minimiser\n",
       "  * gradf   : (Function) le gradient de la fonction f\n",
       "  * hessf   : (Function) la hessienne de la fonction f\n",
       "  * x0      : (Array{Float,1}) première approximation de la solution cherchée\n",
       "  * options : (Array{Float,1})\n",
       "\n",
       "      * max_iter      : le nombre maximal d'iterations\n",
       "      * Tol_abs       : la tolérence absolue\n",
       "      * Tol_rel       : la tolérence relative\n",
       "      * epsilon       : epsilon pour les tests de stagnation\n",
       "\n",
       "#### Sorties:\n",
       "\n",
       "  * xmin    : (Array{Float,1}) une approximation de la solution du problème  : $\\min_{x \\in \\mathbb{R}^{n}} f(x)$\n",
       "  * fmin    : (Float) $f(x_{min})$\n",
       "  * flag    : (Integer) indique le critère sur lequel le programme s'est arrêté (en respectant cet ordre de priorité si plusieurs critères sont vérifiés)\n",
       "\n",
       "      * 0    : CN1\n",
       "      * 1    : stagnation du xk\n",
       "      * 2    : stagnation du f\n",
       "      * 3    : nombre maximal d'itération dépassé\n",
       "  * nb_iters : (Integer) le nombre d'itérations faites par le programme\n",
       "\n",
       "#### Exemple d'appel\n",
       "\n",
       "```@example\n",
       "f(x)=100*(x[2]-x[1]^2)^2+(1-x[1])^2\n",
       "gradf(x)=[-400*x[1]*(x[2]-x[1]^2)-2*(1-x[1]) ; 200*(x[2]-x[1]^2)]\n",
       "hessf(x)=[-400*(x[2]-3*x[1]^2)+2  -400*x[1];-400*x[1]  200]\n",
       "x0 = [1; 0]\n",
       "options = []\n",
       "xmin,fmin,flag,nb_iters = Algorithme_De_Newton(f,gradf,hessf,x0,options)\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[1m  Objet\u001b[22m\n",
       "\u001b[1m  -------\u001b[22m\n",
       "\n",
       "  Cette fonction implémente l'algorithme de Newton pour résoudre un problème\n",
       "  d'optimisation sans contraintes\n",
       "\n",
       "\u001b[1m  Syntaxe\u001b[22m\n",
       "\u001b[1m  ---------\u001b[22m\n",
       "\n",
       "\u001b[36m  xmin,fmin,flag,nb_iters = Algorithme_de_Newton(f,gradf,hessf,x0,option)\u001b[39m\n",
       "\n",
       "\u001b[1m  Entrées :\u001b[22m\n",
       "\u001b[1m  -----------\u001b[22m\n",
       "\n",
       "    •  f : (Function) la fonction à minimiser\n",
       "\n",
       "    •  gradf : (Function) le gradient de la fonction f\n",
       "\n",
       "    •  hessf : (Function) la hessienne de la fonction f\n",
       "\n",
       "    •  x0 : (Array{Float,1}) première approximation de la solution\n",
       "       cherchée\n",
       "\n",
       "    •  options : (Array{Float,1})\n",
       "       • max_iter : le nombre maximal d'iterations\n",
       "       • Tol_abs : la tolérence absolue\n",
       "       • Tol_rel : la tolérence relative\n",
       "       • epsilon : epsilon pour les tests de stagnation\n",
       "\n",
       "\u001b[1m  Sorties:\u001b[22m\n",
       "\u001b[1m  ----------\u001b[22m\n",
       "\n",
       "    •  xmin : (Array{Float,1}) une approximation de la solution du\n",
       "       problème : \u001b[35m\\min_{x \\in \\mathbb{R}^{n}} f(x)\u001b[39m\n",
       "\n",
       "    •  fmin : (Float) \u001b[35mf(x_{min})\u001b[39m\n",
       "\n",
       "    •  flag : (Integer) indique le critère sur lequel le programme s'est\n",
       "       arrêté (en respectant cet ordre de priorité si plusieurs critères\n",
       "       sont vérifiés)\n",
       "       • 0 : CN1\n",
       "       • 1 : stagnation du xk\n",
       "       • 2 : stagnation du f\n",
       "       • 3 : nombre maximal d'itération dépassé\n",
       "\n",
       "    •  nb_iters : (Integer) le nombre d'itérations faites par le\n",
       "       programme\n",
       "\n",
       "\u001b[1m  Exemple d'appel\u001b[22m\n",
       "\u001b[1m  -----------------\u001b[22m\n",
       "\n",
       "\u001b[36m  f(x)=100*(x[2]-x[1]^2)^2+(1-x[1])^2\u001b[39m\n",
       "\u001b[36m  gradf(x)=[-400*x[1]*(x[2]-x[1]^2)-2*(1-x[1]) ; 200*(x[2]-x[1]^2)]\u001b[39m\n",
       "\u001b[36m  hessf(x)=[-400*(x[2]-3*x[1]^2)+2  -400*x[1];-400*x[1]  200]\u001b[39m\n",
       "\u001b[36m  x0 = [1; 0]\u001b[39m\n",
       "\u001b[36m  options = []\u001b[39m\n",
       "\u001b[36m  xmin,fmin,flag,nb_iters = Algorithme_De_Newton(f,gradf,hessf,x0,options)\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "using Documenter\n",
    "using Markdown  \n",
    "include(\"Algorithme_De_Newton.jl\")\n",
    " @doc Algorithme_De_Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Vérifier que les tests ci-dessous passent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:    | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Test algo newton | \u001b[32m  22  \u001b[39m\u001b[36m   22  \u001b[39m\u001b[0m4.7s\n"
     ]
    }
   ],
   "source": [
    "using Test\n",
    "\n",
    "# Tolérance pour les tests d'égalité\n",
    "tol_erreur = sqrt(eps())\n",
    "\n",
    "## ajouter les fonctions de test\n",
    "include(\"../test/fonctions_de_tests.jl\")\n",
    "include(\"../test/tester_algo_newton.jl\")\n",
    "include(\"../src/Algorithme_De_Newton.jl\")\n",
    "\n",
    "affiche = false\n",
    "\n",
    "@testset \"Test algo newton\" begin\n",
    "\t# Tester l'algorithme de Newton\n",
    "\ttester_algo_newton(affiche,Algorithme_De_Newton)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1m Résultats de : Newton appliqué à f0 au point initial -1.5707963267948966:\u001b[22m\u001b[39m\n",
      "  * xsol = -1.5707963267948966\n",
      "  * f(xsol) = -1.0\n",
      "  * nb_iters = 0\n",
      "  * flag = 0\n",
      "  * sol_exacte : -1.5707963267948966\n",
      "\n",
      "\u001b[34m\u001b[1m Résultats de : Newton appliqué à f0 au point initial -1.0707963267948966:\u001b[22m\u001b[39m\n",
      "  * xsol = -1.5707963267949088\n",
      "  * f(xsol) = -1.0\n",
      "  * nb_iters = 3\n",
      "  * flag = 0\n",
      "  * sol_exacte : -1.5707963267948966\n",
      "\n",
      "\u001b[34m\u001b[1m Résultats de : Newton appliqué à f0 au point initial 1.5707963267948966:\u001b[22m\u001b[39m\n",
      "  * xsol = 1.5707963267948966\n",
      "  * f(xsol) = 1.0\n",
      "  * nb_iters = 0\n",
      "  * flag = 0\n",
      "  * sol_exacte : -1.5707963267948966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1m Résultats de : Newton appliqué à f1 au point initial [0, 0, 0]:\u001b[22m\u001b[39m\n",
      "  * xsol = "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 0.9999999999999999]\n",
      "  * f(xsol) = 1.232595164407831e-32\n",
      "  * nb_iters = 1\n",
      "  * flag = 0\n",
      "  * sol_exacte : "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1]\n",
      "\n",
      "\u001b[34m\u001b[1m Résultats de : Newton appliqué à f1 au point initial [-1, 100, 100]:\u001b[22m\u001b[39m\n",
      "  * xsol = [1.0, 1.0, 1.0]\n",
      "  * f(xsol) = 0.0\n",
      "  * nb_iters = 1\n",
      "  * flag = 0\n",
      "  * sol_exacte : [1, 1, 1]\n",
      "\n",
      "\u001b[34m\u001b[1m Résultats de : Newton appliqué à f2 au point initial [0, 0]:\u001b[22m\u001b[39m\n",
      "  * xsol = [1.0, 1.0]\n",
      "  * f(xsol) = 0.0\n",
      "  * nb_iters = 2\n",
      "  * flag = 0\n",
      "  * sol_exacte : [1, 1]\n",
      "\n",
      "\u001b[34m\u001b[1m Résultats de : Newton appliqué à f2 au point initial [1, 100]:\u001b[22m\u001b[39m\n",
      "  * xsol = [1.0, 1.0]\n",
      "  * f(xsol) = 0.0\n",
      "  * nb_iters = 1\n",
      "  * flag = 0\n",
      "  * sol_exacte : [1, 1]\n"
     ]
    },
    {
     "ename": "SingularException",
     "evalue": "SingularException(1)",
     "output_type": "error",
     "traceback": [
      "SingularException(1)\n",
      "\n",
      "Stacktrace:\n",
      " [1] \\(D::Diagonal{Float64, Vector{Float64}}, B::Vector{Float64})\n",
      "   @ LinearAlgebra C:\\Users\\rachi\\AppData\\Local\\Programs\\Julia-1.8.3\\share\\julia\\stdlib\\v1.8\\LinearAlgebra\\src\\diagonal.jl:419\n",
      " [2] \\(A::Matrix{Float64}, B::Vector{Float64})\n",
      "   @ LinearAlgebra C:\\Users\\rachi\\AppData\\Local\\Programs\\Julia-1.8.3\\share\\julia\\stdlib\\v1.8\\LinearAlgebra\\src\\generic.jl:1102\n",
      " [3] Algorithme_De_Newton(f::typeof(f2), gradf::typeof(grad_f2), hessf::typeof(hess_f2), x0::Vector{Float64}, options::Vector{Any})\n",
      "   @ Main c:\\Users\\rachi\\Downloads\\projet-optinum\\src\\Algorithme_De_Newton.jl:65\n",
      " [4] top-level scope\n",
      "   @ c:\\Users\\rachi\\Downloads\\projet-optinum\\src\\algo_newton.ipynb:75"
     ]
    }
   ],
   "source": [
    "#using Pkg; Pkg.add(\"LinearAlgebra\"); Pkg.add(\"Markdown\")\n",
    "# using Documenter\n",
    "using LinearAlgebra\n",
    "using Markdown                             # Pour que les docstrings en début des fonctions ne posent\n",
    "                                           # pas de soucis. Ces docstrings sont utiles pour générer \n",
    "                                           # la documentation sous GitHub\n",
    "include(\"Algorithme_De_Newton.jl\")\n",
    "\n",
    "# Affichage les sorties de l'algorithme des Régions de confiance\n",
    "function my_afficher_resultats(algo,nom_fct,point_init,xmin,fxmin,flag,sol_exacte,nbiters)\n",
    "\tprintstyled(\"\\n Résultats de : \",algo, \" appliqué à \",nom_fct, \" au point initial \", point_init, \":\\n\",bold=true,color=:blue)\n",
    "\tprintln(\"  * xsol = \",xmin)\n",
    "\tprintln(\"  * f(xsol) = \",fxmin)\n",
    "\tprintln(\"  * nb_iters = \",nbiters)\n",
    "\tprintln(\"  * flag = \",flag)\n",
    "\tprintln(\"  * sol_exacte : \", sol_exacte)\n",
    "end\n",
    "\n",
    "# Fonction f0\n",
    "# -----------\n",
    "f0(x) =  sin(x)\n",
    "# la gradient de la fonction f0\n",
    "grad_f0(x) = cos(x)\n",
    "# la hessienne de la fonction f0\n",
    "hess_f0(x) = -sin(x)\n",
    "sol_exacte = -pi/2\n",
    "options = []\n",
    "\n",
    "x0 = sol_exacte\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f0,grad_f0,hess_f0,x0,options)\n",
    "my_afficher_resultats(\"Newton\",\"f0\",x0,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "x0 = -pi/2+0.5\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f0,grad_f0,hess_f0,x0,options)\n",
    "my_afficher_resultats(\"Newton\",\"f0\",x0,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "x0 = pi/2\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f0,grad_f0,hess_f0,x0,options)\n",
    "my_afficher_resultats(\"Newton\",\"f0\",x0,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "\n",
    "\n",
    "# Fonction f1\n",
    "# -----------\n",
    "f1(x) = 2 * (x[1] + x[2] + x[3] - 3) ^ 2 + (x[1] - x[2]) ^ 2 + (x[2] - x[3]) ^ 2\n",
    "# la gradient de la fonction f0\n",
    "grad_f1(x) = [4*(x[1]+x[2]+x[3]-3)+2*(x[1]-x[2]);4*(x[1]+x[2]+x[3]-3)-2*(x[1]-x[2])+2*(x[2]-x[3]);4*(x[1]+x[2]+x[3]-3)-2*(x[2]-x[3])]\n",
    "# la hessienne de la fonction f0\n",
    "hess_f1(x) = [6 2 4; 2 8 2; 4 2 6]\n",
    "sol_exacte = [1 ,1 ,1]\n",
    "options = []\n",
    "\n",
    "x0 = [0,0,0]\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f1,grad_f1,hess_f1,x0,options)\n",
    "my_afficher_resultats(\"Newton\",\"f1\",x0,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "x0 = [-1,100,100]\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f1,grad_f1,hess_f1,x0,options)\n",
    "my_afficher_resultats(\"Newton\",\"f1\",x0,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "\n",
    "\n",
    "\n",
    "#fonction f2\n",
    "f2(x) = 100 * (x[2] - x[1] ^ 2) ^ 2 + (1 - x[1]) ^ 2\n",
    "grad_f2(x) = [-400 * x[1] * (x[2] - x[1] ^ 2) - 2 * (1 - x[1]) ; 200 * (x[2] -x[1]^2)]\n",
    "hess_f2(x) = [(-400*(x[2]-3*x[1]^2)+2) -(400*x[1]);\n",
    "              (-400*x[1]) 200]\n",
    "sol_exacte = [1,1]\n",
    "options = []\n",
    "\n",
    "x0 = [0,0]\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f2,grad_f2,hess_f2,x0,options)\n",
    "my_afficher_resultats(\"Newton\",\"f2\",x0,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "x0 = [1,100]\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f2,grad_f2,hess_f2,x0,options)\n",
    "my_afficher_resultats(\"Newton\",\"f2\",x0,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "\n",
    "x0 = [0,1/200]\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f2,grad_f2,hess_f2,x0,options)\n",
    "my_afficher_resultats(\"Newton\",\"f2\",x0,xmin,f_min,flag,sol_exacte,nb_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interprétation \n",
    "\n",
    "1. Justifier les résultats obtenus pour l'exemple $f_0$ ci-dessus;\n",
    "\n",
    "2. Soit \n",
    "$$ f_{1} : \\mathbb{R}^3 \\rightarrow \\mathbb{R}$$ $$ (x_1,x_2, x_3) \\mapsto  2 (x_1 +x_2 + x_3 -3)^2 + (x_1-x_2)^2 + (x_2 - x_3)^2$$ \n",
    "\n",
    "Justifier que l’algorithme implémenté converge en une itération pour $f_{1}$;\n",
    "\n",
    "3. Soit \n",
    "$$ f_{2} : \\mathbb{R}^2 \\rightarrow \\mathbb{R}$$ $$ (x_1,x_2) \\mapsto 100(x_2-x_1^2)^2 + (1-x_1)^2 $$ \n",
    "\n",
    "Justifier que l’algorithme puisse ne pas converger pour $f_{2}$ avec certains points initiaux.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réponses :\n",
    "\n",
    "1-l'algorithme appliqué à f0 pour un point de départ égale à -pi/2 converge directement \n",
    "vu que le point de départ choisi est bien le min de la fonction sinus. Aussi le point de départ x0= -pi/2+0.5 \n",
    "choisi dans le 2 ème cas assure une convergence rapide vu qu'il est proche du point critique (ici le min) de la fonction \n",
    "sinus.Tandis que pour un point de départ x0 égale à pi/2 qui est un point critique de la fonction sinus,l'algorithme de \n",
    "newton converge vers ce dernier qui est un maximum de la fonction, ainsi dans ce cas il faut vérifier la condition d'ordre 2\n",
    "pour s'assurer qu'on converge vers les mins de la fonction.\n",
    "\n",
    "\n",
    "\n",
    "2-  f : ℝ2 → ℝ est une fonction de classe C2, et est sous une forme quadratique.Ainsi si xsol est un point critique, \n",
    "cette forme, dans le cas où elle est non dégénérée, permet de décider si on a affaire à un point de maximum local,\n",
    "ou à un point de minimum local ou à un point selle.\n",
    "Ainsi, [1,1,1] est un min de f1, on prend donc un point initial x0=[0,0,0]/x0=[-1,100,100] par exemple et on remarque que\n",
    "l'algorithme converge en une itération vers le min de f1\n",
    "\n",
    "3- pour les deux points initiaux, x0=[0,0] et x0=[1,100],l'algorithme converge,tandis que pour des points initiaux,\n",
    "l'lagorithme peut ne pas converger car le système linéaire  hessf*x=-gradf peut ne pas avoir de solutions dans le \n",
    "cas où la hessiene n'est pas inversible.Annulons par exemple le terme -400(x2-3x1^2)+2 pour que la hessienne soit \n",
    "non inversible. Ainsi en prenant le point intial x0=[0 1/200] qui annule le terme précedent on remarque qu'une \n",
    "exception s'est levée, ainsi l'algorithme ne peut pas converger.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d9d52e4e42d889ef44fdd960ad7523bff2f529da33eef29f47a98bbc470680c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
